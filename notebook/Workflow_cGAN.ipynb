{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Challenge Image Analysis - Team 6\n",
    "\n",
    "This notebook shows an example workflow for the proposed image analysis software, it consists of two parts: training and evaluation. More information about the setup and file structure can be found on the Github page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Setup\n",
    "In this part, the general setup for the workflow will be done. This consists of changing the working directory to be `root` and performing relevant imports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the root folder\n",
    "import os, sys\n",
    "if os.path.split(os.getcwd())[-1] != 'TeamChallenge_team6':\n",
    "    %cd ..\n",
    "    \n",
    "    if os.path.split(os.getcwd())[-1] != 'TeamChallenge_team6':\n",
    "        raise UserError(\"Something went wrong in the directory reassignment!\")\n",
    "\n",
    "# Add relevant directories to path\n",
    "if \"\" not in sys.path : sys.path.append(\"\")\n",
    "if \"src\" not in sys.path : sys.path.append(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import os\n",
    "from data_preperation import data_prep, inspect_data\n",
    "from preprocessing import preprocess_data\n",
    "from model import define_discriminator, define_generator, define_gan\n",
    "from training import train\n",
    "from evaluation import evaluate, get_fsl_metrics, resp_vec_correlation\n",
    "from util.tf_session import setup_tf_session\n",
    "from util.general import *\n",
    "\n",
    "# Setup the tf session for possible gpu usage\n",
    "n_gpus = setup_tf_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Training\n",
    "In this part, the cGAN model will be trained. It will do so by first preprocessing the data, after which the datasets will be loaded and the models are defined. Hereafter, the actual training process is performed. By default, we'll be training for 100 epochs with a batch size of 4 and an augmentation factor of 20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a: Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_data(\"data\", verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b: Dataset generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Dataset - TRAIN\")\n",
    "dataset_train, train_subjects = data_prep(os.path.join(\"data\", \"preprocessed\"), True, \"train\", verbose=True)\n",
    "print(\"Dataset - TEST\")\n",
    "dataset_test, test_subjects = data_prep(os.path.join(\"data\", \"preprocessed\"), True, \"test\", verbose=True)\n",
    "\n",
    "# Define image shape\n",
    "image_shape = dataset_train[0].shape[1:]\n",
    "image_shape = (image_shape[0], image_shape[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data inspection\n",
    "We will now also have a look at some of the preprocessed images for quality assurance and a better understanding in the inner workings of the pipeline. Please note that here, the left image is the day 3 image (input), while the right image is the day 0 image (target). You'll notice that the image used are brain extracted and cropped in such a way as to center the brain as much as possible. Also, a histogram equalization is performed to yield better image contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_data(dataset_train, n_samples = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c: Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: We should add Roos's schematic here!\n",
    "\n",
    "# Define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "# Show model summaries\n",
    "print(print_style.BOLD+\"=== DISCRIMINATOR MODEL ===\"+print_style.END)\n",
    "d_model.summary()\n",
    "print(print_style.BOLD+\"\\n\\n===== GENERATOR MODEL =====\"+print_style.END)\n",
    "g_model.summary()\n",
    "print(print_style.BOLD+\"\\n\\n======== GAN MODEL ========\"+print_style.END)\n",
    "gan_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d: Actual training\n",
    "Here, we will run the actual training. Augmentation will be performed by default, with an augmentation factor of 20. The batch size and number of epochs are 4 and 100, respectively. An Adam optimizer is used, and the loss function is comprised of binary crossentropy (discriminator), the mean average error (generator), and a SSIM loss term (1-SSIM) (generator). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "run_name = train(d_model, g_model, gan_model, dataset_train, n_epochs=100, n_batch=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training we did above, we can evaluate the best performing model. First choose which model (based on step) you want to evaluate (e.g. \"0029400\"), you can do this by typing the following into your prompt (with specified path to logs): \n",
    "\n",
    "tensorboard --logdir \"../logs\" \n",
    "\n",
    "and go to http://localhost:6006/\n",
    "\n",
    "The step which resulted in the best performing step can be specified in the specific_model parameter below to evaluate the correpsonding model (\"last\" argument results in evaluating the model from the last step)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation analysis\n",
    "Firstly, let's run our training set through the generator model and calculate the SSIM scores. We will then compare these scores to SSIM and DSC scores from the FSL run (Bart's method) and the response vector data through a correlation analysis. This is done, since it is expected that all of these features will in some way quantify the edema-related deformation in a specific subject. We will display this analysis in a set of scatter plots. Here, it should be noted that the darkness of the plot is directly proportional to the correlation between those two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SSIM for our cGAN method\n",
    "eval_model = \"0000000\"\n",
    "\n",
    "eval_SSIMs = evaluate(d_model, g_model, gan_model, dataset_test, time=run_name, specific_model=eval_model)\n",
    "\n",
    "# Calculate SSIM and DSC for the FSL method (Bart's method)\n",
    "fsl_SSIM, fsl_DSC = get_fsl_metrics(\"data\", test_subjects)\n",
    "\n",
    "# Perform correlation analysis and display figure\n",
    "resp_vec_cor = resp_vec_correlation(\"data\", test_subjects, eval_SSIMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate results\n",
    "Now, let's calculate and display some results for our method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_SSIMs = evaluate(d_model, g_model, gan_model, dataset_test, time=run_name, specific_model=eval_model, show_fig=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the SSIM scores between the true day3 and fake day0 images give a quantification for deformation. Here, note that SSIM is given in a range of `[-1, 1]`. The higher the deformation, the lower this number should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eval_SSIMs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
