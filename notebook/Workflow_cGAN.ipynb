{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Challenge Image Analysis - Team 6\n",
    "\n",
    "This notebook shows an example workflow for the proposed image analysis software, it consists of two parts: training and evaluation. More information about the setup and file structure can be found on the Github page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the root folder\n",
    "import os, sys\n",
    "if os.path.split(os.getcwd())[-1] != 'TeamChallenge_team6':\n",
    "    %cd ..\n",
    "    sys.path.append(\"src\")\n",
    "    \n",
    "    if os.path.split(os.getcwd())[-1] != 'TeamChallenge_team6':\n",
    "        raise UserError(\"Something went wrong in the directory reassignment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import sys\n",
    "if \"\" not in sys.path : sys.path.append(\"\")\n",
    "\n",
    "import os\n",
    "from data_preperation import data_prep\n",
    "from preprocessing import preprocess_data\n",
    "from model import define_discriminator, define_generator, define_gan\n",
    "from training import train\n",
    "from evaluation import evaluate, get_fnirt_DSC, resp_vec_correlation\n",
    "from util.tf_session import setup_tf_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the tf session for possible gpu usage\n",
    "setup_tf_session()\n",
    "\n",
    "# Preprocess data\n",
    "print(\"Step 0: Preprocessing data...\\t\", end=\"\", flush=True)\n",
    "preprocess_data(\"data\")\n",
    "print(\"Completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(\"Step 1: Loading and extracting data...\\n\")\n",
    "\n",
    "print(\"Dataset - TRAIN\")\n",
    "dataset_train, train_subjects = data_prep(os.path.join(\"data\", \"preprocessed\"), True, \"train\")\n",
    "print(\"Dataset - TEST\")\n",
    "dataset_test, test_subjects = data_prep(os.path.join(\"data\", \"preprocessed\"), True, \"test\")\n",
    "\n",
    "image_shape = dataset_train[0].shape[1:]\n",
    "image_shape = (image_shape[0], image_shape[1], 1)\n",
    "\n",
    "print(\"Completed data loading!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "print(\"Step 2: Defining models\")\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "\n",
    "print(\"Defining models completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Step 3: Training\")\n",
    "time = train(d_model, g_model, gan_model, dataset_train, n_epochs=1)\n",
    "print(\"Training completed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the training we did above, we can evaluate the best performing model. First choose which model (based on step) you want to evaluate (e.g. \"0029400\"), you can do this by typing the following into your prompt (with specified path to logs): \n",
    "\n",
    "tensorboard --logdir \"../logs\" \n",
    "\n",
    "and go to http://localhost:6006/\n",
    "\n",
    "The step which resulted in the best performing step can be specified in the specific_model parameter below to evaluate the correpsonding model (\"last\" argument results in evaluating the model from the last step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 4: Evaluation\")\n",
    "eval_SSIMs = evaluate(d_model, g_model, gan_model, dataset_test, time, specific_model=\"0000003\")\n",
    "eval_DSCs = get_fnirt_DSC(\"data\", test_subjects)\n",
    "resp_vec_cor = resp_vec_correlation(\"data\", test_subjects, eval_SSIMs)\n",
    "print(\"Evaluation completed!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# correlatie dingen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
